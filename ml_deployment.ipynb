{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bucket: aipi510-ml-deployment-bucket\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import sagemaker\n",
    "import shutil\n",
    "import tarfile\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import zipfile\n",
    "\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = \"aipi510-ml-deployment-bucket\"\n",
    "print(\"Using Bucket: \" + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/TinyImageNet.zip...\n",
      "Unzipping file...\n",
      "Unzip complete\n"
     ]
    }
   ],
   "source": [
    "# Github URL where the dataset is stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/\"\n",
    "\n",
    "# Create paths if they don't exist yet\n",
    "DATASET_PATH = \"./data\"\n",
    "\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "file_name = \"TinyImageNet.zip\"\n",
    "file_path = os.path.join(DATASET_PATH, file_name)\n",
    "if not os.path.isfile(file_path):\n",
    "    file_url = base_url + file_name\n",
    "    print(f\"Downloading {file_url}...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(file_url, file_path)\n",
    "    except HTTPError as e:\n",
    "        print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n",
    "    if file_name.endswith(\".zip\"):\n",
    "        print(\"Unzipping file...\")\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(file_path.rsplit(\"/\",1)[0])\n",
    "            print(\"Unzip complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset and Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and create data loader\n",
    "imagenet_path = os.path.join(DATASET_PATH, \"TinyImageNet/\")\n",
    "assert os.path.isdir(imagenet_path), f\"Could not find the ImageNet dataset at expected path \\\"{imagenet_path}\\\". \" + \\\n",
    "                                     f\"Please make sure to have downloaded the ImageNet dataset here, or change the {DATASET_PATH=} variable.\"\n",
    "\n",
    "# Load label names to interpret the label numbers 0 to 999\n",
    "with open(os.path.join(imagenet_path, \"label_list.json\"), \"r\") as f:\n",
    "    label_names = json.load(f)\n",
    "\n",
    "# get a list of folders in sorted order for retrieving pictures by label\n",
    "folders = sorted([f for f in os.listdir(imagenet_path) if os.path.isdir(os.path.join(imagenet_path, f))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet-50 model pre-trained on ImageNet\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "# Define file paths\n",
    "pth_path = './resnet50.pth'\n",
    "tar_path = './model.tar.gz'\n",
    "\n",
    "# Save as .pth if it doesn't exist\n",
    "if not os.path.exists(pth_path):\n",
    "    print(f\"Saving model to {pth_path}\")\n",
    "    torch.save(model.state_dict(), pth_path)\n",
    "    print(\"Model saved as .pth file\")\n",
    "\n",
    "# Create .tar.gz if it doesn't exist\n",
    "if not os.path.exists(tar_path):\n",
    "    print(f\"Creating {tar_path}\")\n",
    "    # Create a temporary directory for the tar file\n",
    "    temp_dir = './temp'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy the .pth file to temp directory\n",
    "    temp_pth = os.path.join(temp_dir, 'resnet50.pth')\n",
    "    shutil.copy2(pth_path, temp_pth)\n",
    "    \n",
    "    # Create the tar.gz file\n",
    "    with tarfile.open(tar_path, \"w:gz\") as tar:\n",
    "        tar.add(temp_pth, arcname='resnet50.pth')\n",
    "    \n",
    "    # Clean up temporary directory\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(\"Model saved as .tar.gz file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Images For a Specific Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(label_name):\n",
    "    '''\n",
    "    gets a list of images in RGB format by label name from the TinyImageNet dataset\n",
    "\n",
    "    Inputs:\n",
    "        label_name (str): the label for which to retrieve the images\n",
    "\n",
    "    Return:\n",
    "        images (list): a list of the images retrieved\n",
    "    '''\n",
    "    #get the index of the label from label_list.json\n",
    "    index = label_names.index(label_name)\n",
    "\n",
    "    #get the corresponding folder of images from TinyImageNet\n",
    "    folder = imagenet_path + folders[index] + '/'\n",
    "\n",
    "    #get the images from the selected folder\n",
    "    image_names = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "    images = []\n",
    "    for image_name in image_names:\n",
    "        #open the image\n",
    "        with open(os.path.relpath(folder + image_name), 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                #convert the image to RGB and add it to the output list\n",
    "                images.append(img.convert('RGB'))\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wallaby\n"
     ]
    }
   ],
   "source": [
    "#get the images by label\n",
    "images_rgb = get_images('wallaby')\n",
    "img = images_rgb[0]\n",
    "img_tensor = img_transform(img).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    output = model(img_tensor)\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "_, predicted_class = probabilities.max(0)\n",
    "print(label_names[predicted_class.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_data_prefix = \"sagemaker/data\"\n",
    "data = sess.upload_data(\n",
    "    path=\"./data\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=sm_data_prefix\n",
    ")\n",
    "\n",
    "sm_model_prefix = \"sagemaker/model\"\n",
    "data = sess.upload_data(\n",
    "    path=\"model.tar.gz\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=sm_model_prefix\n",
    ")\n",
    "\n",
    "data = sess.upload_data(\n",
    "    path=\"resnet50.pth\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=sm_model_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write The Script.py File to Deploy To SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load model once and set to evaluation mode\n",
    "    model = models.resnet50()\n",
    "    model.load_state_dict(torch.load(os.path.join(model_dir, 'model.pth')))\n",
    "    model.eval()\n",
    "    \n",
    "    # Load label names only once\n",
    "    with open(os.path.join(model_dir, \"label_list.json\"), \"r\") as f:\n",
    "        label_names = json.load(f)\n",
    "\n",
    "    folders = sorted([f for f in os.listdir(imagenet_path) if os.path.isdir(os.path.join(imagenet_path, f))])\n",
    "    \n",
    "    # Return both model and label names\n",
    "    return model, folders, label_names\n",
    "\n",
    "def get_images(imagenet_path, folders, label_name):\n",
    "    '''\n",
    "    gets a list of images in RGB format by label name from the TinyImageNet dataset\n",
    "\n",
    "    Inputs:\n",
    "        label_name (str): the label for which to retrieve the images\n",
    "\n",
    "    Return:\n",
    "        images (list): a list of the images retrieved\n",
    "    '''\n",
    "    #get the index of the label from label_list.json\n",
    "    index = label_names.index(label_name)\n",
    "\n",
    "    #get the corresponding folder of images from TinyImageNet\n",
    "    folder = imagenet_path + folders[index] + '/'\n",
    "\n",
    "    #get the images from the selected folder\n",
    "    image_names = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "    images = []\n",
    "    for image_name in image_names:\n",
    "        #open the image\n",
    "        with open(os.path.relpath(folder + image_name), 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                #convert the image to RGB and add it to the output list\n",
    "                images.append(img.convert('RGB'))\n",
    "\n",
    "    return images\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def predict_fn(input_data, model, label_names):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        _, predicted_class = probabilities.max(0)\n",
    "        \n",
    "        # Return the label corresponding to the predicted class\n",
    "        return label_names[predicted_class.item()]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load label names from a json file\n",
    "    DATASET_PATH = \"./data\"\n",
    "    imagenet_path = os.path.join(DATASET_PATH, \"TinyImageNet/\")\n",
    "    \n",
    "    # Load the model\n",
    "    model, folders, label_names = model_fn(\"./resnet50.pth\")\n",
    "\n",
    "    # get image and transform it\n",
    "    img_transform = get_transform()\n",
    "    images_rgb = get_images(imagenet_path=imagenet_path, folders=folders, label_name='wallaby')\n",
    "    img = images_rgb[0]\n",
    "    input_data = img_transform(img).unsqueeze(0)\n",
    "\n",
    "    # Run prediction\n",
    "    predicted_label = predict_fn(input_data, model, label_names)\n",
    "    print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model_artifact = \"s3://aipi510-ml-deployment-bucket/sagemaker/model/model.tar.gz\"\n",
    "role = \"arn:aws:iam::567126052638:role/service-role/AmazonSageMaker-ExecutionRole-20241001T175836\"\n",
    "\n",
    "# Create the SageMaker PyTorchModel\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artifact,\n",
    "    role=role,\n",
    "    entry_point=\"script.py\",  # Your inference script\n",
    "    framework_version=\"1.9\",  # Update based on your PyTorch version\n",
    "    py_version=\"py38\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-inference-2024-11-01-19-38-07-465 in account 567126052638 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m input_data \u001b[38;5;241m=\u001b[39m img_transform(img)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Preprocess your image data as needed\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "File \u001b[0;32m~/Documents/AIPI_510/TeamAssignment8/ml-deployment/venv/lib/python3.9/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m~/Documents/AIPI_510/TeamAssignment8/ml-deployment/venv/lib/python3.9/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIPI_510/TeamAssignment8/ml-deployment/venv/lib/python3.9/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-inference-2024-11-01-19-38-07-465 in account 567126052638 for more information."
     ]
    }
   ],
   "source": [
    "images_rgb = get_images('wallaby')\n",
    "img = images_rgb[0]\n",
    "input_data = img_transform(img).unsqueeze(0)\n",
    "\n",
    "# Preprocess your image data as needed\n",
    "prediction = predictor.predict(input_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
