{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bucket: ta-ml-deployment-sagemaker\n",
      "In region: us-east-2\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import sagemaker\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "#Dataset \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import zipfile\n",
    "\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = \"ta-ml-deployment-sagemaker\"\n",
    "print(\"Using Bucket: \" + bucket)\n",
    "print(f\"In region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Create a dataframe with feature names\n",
    "df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "\n",
    "# Add target column\n",
    "df['target'] = breast_cancer.target\n",
    "\n",
    "# Split features (X) and target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['target'] = y_train\n",
    "X_test['target'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"train-v-1.csv\", index=False)\n",
    "X_test.to_csv(\"test-v-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload to S3 bucket successful!\n",
      "\n",
      "trainpath = s3://ta-ml-deployment-sagemaker/sagemaker/breast-cancer/train-v-1.csv\n",
      "testpath = s3://ta-ml-deployment-sagemaker/sagemaker/breast-cancer/test-v-1.csv\n"
     ]
    }
   ],
   "source": [
    "sm_data_prefix = \"sagemaker/breast-cancer\"\n",
    "#Upload the train data\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"train-v-1.csv\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=sm_data_prefix\n",
    ")\n",
    "\n",
    "#upload the test data\n",
    "testpath = sess.upload_data(\n",
    "    path='test-v-1.csv',\n",
    "    bucket=bucket,\n",
    "    key_prefix=sm_data_prefix\n",
    ")\n",
    "\n",
    "print(\"Upload to S3 bucket successful!\\n\")\n",
    "print(f\"trainpath = {trainpath}\")\n",
    "print(f\"testpath = {testpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write The Script.py File to Deploy To SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import sklearn\n",
    "import pathlib\n",
    "import json\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import os\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load model once and set to evaluation mode\n",
    "    model = joblib.load(os.path.join(model_dir, 'model.joblib'))\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print(\"[INFO] Extracting args...\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    #Model hyperparameter\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=100)\n",
    "    parser.add_argument(\"--random_state\", type=int, default=42)\n",
    "\n",
    "    #Directories as arguments\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train_file\", type=str, default=\"train-v-1.csv\")\n",
    "    parser.add_argument(\"--test_file\", type=str, default=\"test-v-1.csv\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"[INFO] Reading data...\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    features = list(train_df.columns)\n",
    "    label = features.pop(-1)\n",
    "\n",
    "    print(\"[INFO] Train, test, features, and labels successfully extracted!\\n\")\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "    y_train = train_df[label]\n",
    "    y_test = test_df[label]\n",
    "\n",
    "    print(f\"Features columns: {features}\")\n",
    "    print(f\"Label column: {label}\\n\")\n",
    "\n",
    "    print(\"[INFO] Training RandomForest Classifier...\\n\")\n",
    "    model = RandomForestClassifier(n_estimators=args.n_estimators, random_state=args.random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    model_path = os.path.join(args.model_dir, 'model.joblib')\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    print(f\"Model path: {model_path}\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    print(\"[INFO] METRIC RESULTS ON TEST DATA\\n\")\n",
    "    print(f\"Test accuracy: {acc}\")\n",
    "    print(f\"Test precision: {precision}\")\n",
    "    print(f\"Test recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='script.py',\n",
    "    role=\"arn:aws:iam::361769570735:role/ta-ml-deployment\",\n",
    "    instance_count=1,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 100,\n",
    "        \"random_state\": 42\n",
    "    },\n",
    "    base_job_name=\"RF-custom-sklearn\",\n",
    "    use_spot_instance=True,\n",
    "    # max_wait=7200,\n",
    "    # max_run=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: RF-custom-sklearn-2024-11-12-04-14-58-968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-12 04:15:03 Starting - Starting the training job...\n",
      "2024-11-12 04:15:17 Starting - Preparing the instances for training...\n",
      "2024-11-12 04:15:59 Downloading - Downloading the training image.....2024-11-12 04:16:51,218 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "2024-11-12 04:16:51,222 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-11-12 04:16:51,269 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "2024-11-12 04:16:51,458 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-11-12 04:16:51,472 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-11-12 04:16:51,485 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-11-12 04:16:51,494 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"n_estimators\": 100,\n",
      "        \"random_state\": 42\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"RF-custom-sklearn-2024-11-12-04-14-58-968\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-361769570735/RF-custom-sklearn-2024-11-12-04-14-58-968/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"n_estimators\":100,\"random_state\":42}\n",
      "SM_USER_ENTRY_POINT=script.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_MODULE_NAME=script\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-2-361769570735/RF-custom-sklearn-2024-11-12-04-14-58-968/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"n_estimators\":100,\"random_state\":42},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"RF-custom-sklearn-2024-11-12-04-14-58-968\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-361769570735/RF-custom-sklearn-2024-11-12-04-14-58-968/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\n",
      "SM_USER_ARGS=[\"--n_estimators\",\"100\",\"--random_state\",\"42\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_N_ESTIMATORS=100\n",
      "SM_HP_RANDOM_STATE=42\n",
      "PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "Invoking script with the following command:\n",
      "/miniconda3/bin/python script.py --n_estimators 100 --random_state 42\n",
      "[INFO] Extracting args...\n",
      "[INFO] Reading data...\n",
      "[INFO] Train, test, features, and labels successfully extracted!\n",
      "Features columns: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Label column: target\n",
      "[INFO] Training RandomForest Classifier...\n",
      "Model path: /opt/ml/model/model.joblib\n",
      "[INFO] METRIC RESULTS ON TEST DATA\n",
      "Test accuracy: 0.9534883720930233\n",
      "Test precision: 0.9534883720930233\n",
      "Test recall: 0.9814814814814815\n",
      "2024-11-12 04:16:52,864 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-11-12 04:17:08 Training - Training image download completed. Training in progress.\n",
      "2024-11-12 04:17:08 Uploading - Uploading generated training model\n",
      "2024-11-12 04:17:08 Completed - Training job completed\n",
      "Training seconds: 89\n",
      "Billable seconds: 89\n"
     ]
    }
   ],
   "source": [
    "#launch the training job that we just created \n",
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-11-12 04:17:08 Starting - Preparing the instances for training\n",
      "2024-11-12 04:17:08 Downloading - Downloading the training image\n",
      "2024-11-12 04:17:08 Training - Training image download completed. Training in progress.\n",
      "2024-11-12 04:17:08 Uploading - Uploading generated training model\n",
      "2024-11-12 04:17:08 Completed - Training job completed\n",
      "Model output path: s3://sagemaker-us-east-2-361769570735/RF-custom-sklearn-2024-11-12-04-14-58-968/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "model_output = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(f\"Model output path: {model_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy of the model output for versioning purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"RandomForestClassifier-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model = SKLearnModel(\n",
    "    name = model_name,\n",
    "    model_data = model_output,\n",
    "    role=\"arn:aws:iam::361769570735:role/ta-ml-deployment\",\n",
    "    entry_point=\"script.py\",\n",
    "    framework_version=FRAMEWORK_VERSION\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Endpoint=RandomForestClassifier-sklearn-model-2024-11-12-04-17-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: RandomForestClassifier-sklearn-model-2024-11-12-04-17-28\n",
      "INFO:sagemaker:Creating endpoint-config with name RandomForestClassifier-sklearn-model-2024-11-12-04-17-28\n",
      "INFO:sagemaker:Creating endpoint with name RandomForestClassifier-sklearn-model-2024-11-12-04-17-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"RandomForestClassifier-sklearn-model-\"+ strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model Endpoint={}\".format(endpoint_name))\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(X_test[0:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting endpoint cause money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
